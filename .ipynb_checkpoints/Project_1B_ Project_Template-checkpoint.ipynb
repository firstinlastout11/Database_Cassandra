{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hoonna/OneDrive/OneDrive - Georgia Institute of Technology/Georiga_Tech/Spring 2020/Data_Engineering/Course1/Project2/SparkifyDatabaseCassandra\n"
     ]
    }
   ],
   "source": [
    "# Checking the current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path andn roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows 8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = []\n",
    "\n",
    "# for each filepath in the file path list\n",
    "for f in file_path_list:\n",
    "    \n",
    "    # reading csv feil\n",
    "    with open(f, 'r', encoding ='utf8',newline='') as csvfile:\n",
    "        #creating a csv reader object\n",
    "        csvreader=csv.reader(csvfile)\n",
    "        next(csvreader)\n",
    "        \n",
    "        #extracting each data row one by one and append it\n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line)\n",
    "print(\"total number of rows\",len(full_data_rows_list))\n",
    "#print(\"data\",full_data_rows_list)\n",
    "\n",
    "#creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the\\\n",
    "#Apache Cassandra tables\n",
    "csv.register_dialect('myDialect',quoting=csv.QUOTE_ALL, skipinitialspace = True)\n",
    "\n",
    "with open('event_datafile_new.csv','w',encoding ='utf8',newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                    'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if(row[0]==''):\n",
    "            continue\n",
    "        writer.writerow((row[0],row[2],row[3],row[4],row[5],row[6],row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv','r',encoding='utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Apache Cassandra coding\n",
    "\n",
    "## Data description\n",
    "It contains music-streaming log data by users. Below are the features of the dataset\n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a connection to a Cassandra instance\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# a session is needed to establish connection and begin executing queries\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1141e10f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a kespace\n",
    "session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS project2\n",
    "WITH REPLICATION =\n",
    "{'class':'SimpleStrategy','replication_factor':1}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set KEYSPACE to the keyspace created (project2)\n",
    "session.set_keyspace('project2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 : Getting the aritist, song title and song's length in the dataset with session_id = 338 and itemInSessino=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this table, the composite key of session id and item in session was used as a primary key. \n",
    "Since these two keys uniquely define each row of the data and there is no sorting necessary, i did not add any more clustering column.\n",
    "For the columns, along with session id and item in session, i used artist name, song title nad song duration which are needed to output the result.\n",
    "I belive that session id and item in session are usually in numbers not text, i set the data type as int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1141de160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_app_history\"\n",
    "query = query + \"(sessionId int, itemInSession int, artist_name text, song_title text, song_length text, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into table\n",
    "Insert the corresponding information from our csv file. \n",
    "Since the original csv file have session id and item in session as strings, i changed them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# store the file name\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    # to skip the header\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        # Insert statement\n",
    "        query = \"INSERT INTO music_app_history (sessionId, itemInSession, artist_name, song_title, song_length)\"\n",
    "        query = query + \"VALUES (%s,%s,%s,%s,%s)\"\n",
    "        \n",
    "        # Match the data and the table accordingly\n",
    "        session.execute(query, (int(line[8]),int(line[3]),line[0],line[9],line[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification of the data insert by using SELECT query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "# Validation of the table\n",
    "\n",
    "query = \"SELECT artist_name, song_title, song_length FROM music_app_history \"\n",
    "query = query + \"WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print(row.artist_name, row.song_title, row.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 : Getting the artist_name, song title and user name for userid = 10, sessinoid =182, in the sorted order by itemInSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this table, the composite key of user id, session id and item in session are used.\n",
    "Partition key of (user_id, session_id) was used to uniquely identify each row of the data.\n",
    "Item in session is used because the output needs to be sorted by iteminsesison.\n",
    "Since the composite key uniquely defines each row of the data, i did not additional clustering columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1141cb550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#drop if exists\n",
    "session.execute(\"DROP TABLE IF EXISTS song_playlist_session\")\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_playlist_session \"\n",
    "query = query + \"(userId int, sessionId int, itemInSession int, artist_name text, song_title text, first_name text, last_name text, PRIMARY KEY ((userId, sessionId), itemInSession))\"\n",
    "session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Insertion\n",
    "Insert the corresponding information from our csv file. \n",
    "Since the original csv file have session id,item in session, and user id as strings, i changed them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the file name\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        # Insert statement\n",
    "        query = \"INSERT INTO song_playlist_session (userId, sessionId, itemInSession, artist_name, song_title, first_name, last_name) \"\n",
    "        query = query + \"VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        \n",
    "        # to match the data and the table accordingly\n",
    "        session.execute(query, (int(line[10]),int(line[8]),int(line[3]),line[0],line[9],line[1], line[4]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation by SELECT query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# Validation step\n",
    "query = \"SELECT artist_name, song_title, first_name, last_name FROM song_playlist_session \"\n",
    "query = query + \"WHERE userId = 10 AND sessionId = 182\"\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print(row.artist_name, row.song_title, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task3: Getting user name who listened to the song 'All Hands Against  His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the table, i used the composite key of song_title, userId and song_length as the primary key.\n",
    "The primary key uniquely defines each row of the data.\n",
    "There is no sorting needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1133adcc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"DROP TABLE IF EXISTS listener_name_table\")\n",
    "query = \"CREATE TABLE IF NOT EXISTS listener_name_table\"\n",
    "query = query + \" (song_title text, userId int, song_length  text, f_name text, l_name text, PRIMARY KEY (song_title, userId, song_length))\"\n",
    "\n",
    "session.execute(query)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Data\n",
    "Insert the corresponding information from our csv file. \n",
    "Since the original csv file have session id and item in session as strings, i changed them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the file name\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO listener_name_table (song_title, userId, song_length, f_name, l_name)\"\n",
    "        query = query + \" VALUES (%s,%s,%s,%s,%s)\"\n",
    "        \n",
    "        session.execute(query, (line[9],int(line[10]),line[5],line[1],line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation through SELECT query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "query = \"SELECT f_name, l_name FROM listener_name_table \"\n",
    "query = query + \"WHERE song_title = 'All Hands Against His Own'\"\n",
    "\n",
    "rows = session.execute(query)\n",
    "for row in rows:\n",
    "    print(row.f_name, row.l_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x112aa7e48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"DROP TABLE IF EXISTS music_app_history1\")\n",
    "session.execute(\"DROP TABLE IF EXISTS song_playlist_sesion\")\n",
    "session.execute(\"DROP TABLE IF EXISTS listener_name_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
